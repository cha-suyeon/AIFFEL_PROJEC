{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5YWLxQpbPs0"
      },
      "source": [
        "# Exploration 15\n",
        "\n",
        "## 프로젝트: 한국어 데이터로 챗봇 만들기\n",
        "### |프로젝트 학습 과정\n",
        "\n",
        "1. 데이터 수집하기\n",
        "2. 데이터 전처리\n",
        "3. SubwordTextEncoder 사용하기\n",
        "4. 모델 구성하기\n",
        "5. 모델 평가하기\n",
        "\n",
        "\n",
        "### |프로젝트 평가\n",
        "| |평가문항|상세기준|\n",
        "|------|---|---|\n",
        "|1|한국어 전처리를 통해 학습 데이터셋을 구축하였다.|공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.|\n",
        "|2|트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.|구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.|\n",
        "|3|한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다.|한국어 입력문장에 그럴듯한 한국어로 답변을 리턴하였다.|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL1fpI5kbT3j"
      },
      "source": [
        "# Data Info\n",
        "\n",
        "## Data description\n",
        "인공데이터입니다.일부 이별과 관련된 질문에서 다음카페 \"사랑보다 아름다운 실연([링크](http://cafe116.daum.net/_c21_/home?grpid=1bld ))에서 자주 나오는 이야기들을 참고하여 제작하였습니다. 가령 \"이별한 지 열흘(또는 100일) 되었어요\"라는 질문에 챗봇이 위로한다는 취지로 답변을 작성하였습니다.\n",
        "\n",
        "1. 챗봇 트레이닝용 문답 페어 11,876개\n",
        "2. 일상다반서 0, 이별(부정) 1, 사랑(긍정) 2로 레이블링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nrw9KVoQbvny"
      },
      "source": [
        "# 1. 데이터 수집\n",
        "\n",
        "한국어 챗봇 데이터는 송영숙님이 공개한 챗봇 데이터를 사용할 예정입니다.\n",
        "데이터는 아래의 링크에서 다운로드 가능합니다.\n",
        "\n",
        "[songys/Chatbot_data](https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH_dlahz9Y39"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCUHZtc-Adb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "78fa37a1-5ae4-4602-cab9-4e2788d2c4bf"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/AIFFEL/ChatbotData.csv')\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11823, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Q            A  label\n",
              "0           12시 땡!   하루가 또 가네요.      0\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "4          PPL 심하네   눈살이 찌푸려지죠.      0"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckoT2gjkCMiV",
        "outputId": "8c011e62-1b46-450e-b25b-361435ec7fcf"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11823 entries, 0 to 11822\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Q       11823 non-null  object\n",
            " 1   A       11823 non-null  object\n",
            " 2   label   11823 non-null  int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 277.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWzCgMnxbydS"
      },
      "source": [
        "# 2. 데이터 전처리\n",
        "\n",
        "## 결측치 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c9elCdpCSr6",
        "outputId": "3a7fd4ab-adf9-4107-f9ad-01a43df5154e"
      },
      "source": [
        "data.isna().sum()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Q        0\n",
              "A        0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGF5LLIeb1o6"
      },
      "source": [
        "## 중복값 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "COenY2zLCUMi",
        "outputId": "1eafb914-8947-44e3-af09-38a60fd4be4f"
      },
      "source": [
        "data[data.duplicated('Q') == True]"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>고양이 키우고 싶어</td>\n",
              "      <td>가족들과 상의해보세요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>공시 준비 힘들어</td>\n",
              "      <td>잘 될 거예요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1294</th>\n",
              "      <td>돈 벌고 싶어</td>\n",
              "      <td>많이 벌수록 좋아요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1445</th>\n",
              "      <td>로또 번호 알려줘</td>\n",
              "      <td>알면 제가 하죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1481</th>\n",
              "      <td>마음이 울적해</td>\n",
              "      <td>거리를 걸어보세요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11642</th>\n",
              "      <td>착해서 잘해주는 건지 좋아하는 건지</td>\n",
              "      <td>헷갈린다고 말해보세요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11649</th>\n",
              "      <td>첫 눈에 반하는게 가능해?</td>\n",
              "      <td>당연히 가능하죠.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11658</th>\n",
              "      <td>첫사랑 생각나</td>\n",
              "      <td>지금의 사랑에 충실하세요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11732</th>\n",
              "      <td>커플여행이 나을까 그냥 우리끼리 갈까?</td>\n",
              "      <td>저는 둘이 가는 게 좋아요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11819</th>\n",
              "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
              "      <td>훔쳐보는 거 티나나봐요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>161 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Q                A  label\n",
              "196               고양이 키우고 싶어     가족들과 상의해보세요.      0\n",
              "235                공시 준비 힘들어         잘 될 거예요.      0\n",
              "1294                 돈 벌고 싶어      많이 벌수록 좋아요.      0\n",
              "1445               로또 번호 알려줘        알면 제가 하죠.      0\n",
              "1481                 마음이 울적해       거리를 걸어보세요.      0\n",
              "...                      ...              ...    ...\n",
              "11642    착해서 잘해주는 건지 좋아하는 건지     헷갈린다고 말해보세요.      2\n",
              "11649         첫 눈에 반하는게 가능해?        당연히 가능하죠.      2\n",
              "11658                첫사랑 생각나   지금의 사랑에 충실하세요.      2\n",
              "11732  커플여행이 나을까 그냥 우리끼리 갈까?  저는 둘이 가는 게 좋아요.      2\n",
              "11819         훔쳐보는 것도 눈치 보임.    훔쳐보는 거 티나나봐요.      2\n",
              "\n",
              "[161 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "ktZg_SThCVBQ",
        "outputId": "f9c9e0eb-e108-4058-c5f9-e060f27f5551"
      },
      "source": [
        "data[data['Q'] == '공시 준비 힘들어']"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>공시 준비 힘들어</td>\n",
              "      <td>합격 기원해요!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>공시 준비 힘들어</td>\n",
              "      <td>잘 될 거예요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Q         A  label\n",
              "234  공시 준비 힘들어  합격 기원해요!      0\n",
              "235  공시 준비 힘들어  잘 될 거예요.      0"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "5wIqWI5tCV8W",
        "outputId": "06c0e87f-b826-4e01-bbdc-39b099ac14cf"
      },
      "source": [
        "data[data.duplicated('A') == True]"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SD카드 안돼</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
              "      <td>시간을 정하고 해보세요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>가끔 뭐하는지 궁금해</td>\n",
              "      <td>그 사람도 그럴 거예요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>가스불 켜놓고 나온거 같아</td>\n",
              "      <td>빨리 집에 돌아가서 끄고 나오세요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11806</th>\n",
              "      <td>혼자만 설레고 혼자서 끝내는 짝사랑 그만할래.</td>\n",
              "      <td>맘고생 많았어요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11807</th>\n",
              "      <td>화이트데이에 고백할까요?</td>\n",
              "      <td>선물을 주면서 솔직하고 당당하게 고백해보세요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11809</th>\n",
              "      <td>확실히 날 좋아하는 걸 아는 남자랑 친구가 될 수 있을까?</td>\n",
              "      <td>그 사람을 위해서는 그러면 안돼요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11816</th>\n",
              "      <td>회식하는데 나만 챙겨줘. 썸임?</td>\n",
              "      <td>호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11822</th>\n",
              "      <td>힘들어서 결혼할까봐</td>\n",
              "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4044 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      Q  ... label\n",
              "3                       3박4일 정도 놀러가고 싶다  ...     0\n",
              "6                               SD카드 안돼  ...     0\n",
              "9                     SNS 시간낭비인데 자꾸 보게됨  ...     0\n",
              "12                          가끔 뭐하는지 궁금해  ...     0\n",
              "18                       가스불 켜놓고 나온거 같아  ...     0\n",
              "...                                 ...  ...   ...\n",
              "11806         혼자만 설레고 혼자서 끝내는 짝사랑 그만할래.  ...     2\n",
              "11807                     화이트데이에 고백할까요?  ...     2\n",
              "11809  확실히 날 좋아하는 걸 아는 남자랑 친구가 될 수 있을까?  ...     2\n",
              "11816                 회식하는데 나만 챙겨줘. 썸임?  ...     2\n",
              "11822                        힘들어서 결혼할까봐  ...     2\n",
              "\n",
              "[4044 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "zyDCVu45CXCw",
        "outputId": "2c394066-076c-446d-f9c8-5d70cc96fda2"
      },
      "source": [
        "data[data['A'] == '선물을 주면서 솔직하고 당당하게 고백해보세요.']"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9783</th>\n",
              "      <td>발렌타인데이에 고백할까요?</td>\n",
              "      <td>선물을 주면서 솔직하고 당당하게 고백해보세요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9820</th>\n",
              "      <td>빼빼로데이에 고백할까요?</td>\n",
              "      <td>선물을 주면서 솔직하고 당당하게 고백해보세요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11807</th>\n",
              "      <td>화이트데이에 고백할까요?</td>\n",
              "      <td>선물을 주면서 솔직하고 당당하게 고백해보세요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Q                          A  label\n",
              "9783   발렌타인데이에 고백할까요?  선물을 주면서 솔직하고 당당하게 고백해보세요.      2\n",
              "9820    빼빼로데이에 고백할까요?  선물을 주면서 솔직하고 당당하게 고백해보세요.      2\n",
              "11807   화이트데이에 고백할까요?  선물을 주면서 솔직하고 당당하게 고백해보세요.      2"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oBACuInCZj1"
      },
      "source": [
        "위의 True 값이 나오는 Q, A의 예시처럼 key를 하나의 컬럼으로만 기준을 잡으면, 각각의 Questions과 Answers이 다른 경우가 발생한다. 챗봇 데이터는 Questions과 Answers이 짝을 이루는 병렬 데이터이기 때문에 각각의 Q, A이 같다고 하여서 무조건적인 삭제는 어렵다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaRaDiLOb45-"
      },
      "source": [
        "## 텍스트 전처리 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdw9qvihCX0b"
      },
      "source": [
        "# 전처리 함수\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip()\n",
        "\n",
        "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
        "    # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
        "    # student와 온점 사이에 거리를 만듭니다.\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "\n",
        "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
        "    sentence = re.sub(r\"[^ㄱ-ㅣ가-힣a-zA-Z0-9?.!,]+\", \" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    return sentence"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsGQq03RCa2r",
        "outputId": "7eee10fa-baa7-4f8a-bff6-fd7f27e8a2bd"
      },
      "source": [
        "questions = data['Q'] # 질문 컬럼만 뽑아내기\n",
        "questions"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                         12시 땡!\n",
              "1                    1지망 학교 떨어졌어\n",
              "2                   3박4일 놀러가고 싶다\n",
              "3                3박4일 정도 놀러가고 싶다\n",
              "4                        PPL 심하네\n",
              "                  ...           \n",
              "11818             훔쳐보는 것도 눈치 보임.\n",
              "11819             훔쳐보는 것도 눈치 보임.\n",
              "11820                흑기사 해주는 짝남.\n",
              "11821    힘든 연애 좋은 연애라는게 무슨 차이일까?\n",
              "11822                 힘들어서 결혼할까봐\n",
              "Name: Q, Length: 11823, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVkt2NlXG_pO",
        "outputId": "d2c26c00-bf0c-4a6f-8f27-2f8180b0e412"
      },
      "source": [
        "questions = questions.values # 인덱스 없는 값만 뽑아내기\n",
        "questions"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['12시 땡!', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', ..., '흑기사 해주는 짝남.',\n",
              "       '힘든 연애 좋은 연애라는게 무슨 차이일까?', '힘들어서 결혼할까봐'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPNEQ9zsG_sM",
        "outputId": "3cb9f357-0f81-4246-ac96-70b74a59610e"
      },
      "source": [
        "questions = list(map(preprocess_sentence, questions)) # 리스트에서 하나씩 뽑아서 함수적용\n",
        "questions[:10]"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['12시 땡 !',\n",
              " '1지망 학교 떨어졌어',\n",
              " '3박4일 놀러가고 싶다',\n",
              " '3박4일 정도 놀러가고 싶다',\n",
              " 'ppl 심하네',\n",
              " 'sd카드 망가졌어',\n",
              " 'sd카드 안돼',\n",
              " 'sns 맞팔 왜 안하지ㅠㅠ',\n",
              " 'sns 시간낭비인 거 아는데 매일 하는 중',\n",
              " 'sns 시간낭비인데 자꾸 보게됨']"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZcucBr3G_vZ",
        "outputId": "e99e279e-1c45-420d-b295-d83739b8fd98"
      },
      "source": [
        "answers = list(map(preprocess_sentence, data['A'].values))\n",
        "answers[:10]"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['하루가 또 가네요 .',\n",
              " '위로해 드립니다 .',\n",
              " '여행은 언제나 좋죠 .',\n",
              " '여행은 언제나 좋죠 .',\n",
              " '눈살이 찌푸려지죠 .',\n",
              " '다시 새로 사는 게 마음 편해요 .',\n",
              " '다시 새로 사는 게 마음 편해요 .',\n",
              " '잘 모르고 있을 수도 있어요 .',\n",
              " '시간을 정하고 해보세요 .',\n",
              " '시간을 정하고 해보세요 .']"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqV5RbQ5G_xL",
        "outputId": "fa841caf-f053-4d7d-e199-3100d8ca8ceb"
      },
      "source": [
        "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
        "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
            "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w8q6rX5cAKd"
      },
      "source": [
        "# 3. SubwordTextEncoder 사용하기\n",
        "\n",
        "질문과 답변의 셋을 각각 questions와 answers에 저장하였으므로 본격적으로 전처리를 진행!\n",
        "\n",
        "### 전처리 과정 요약\n",
        "1. TensorFlow Datasets **SubwordTextEncoder**를 토크나이저로 사용한다.   \n",
        "    단어보다 더 작은 단위인 Subword를 기준으로 토크나이징하고,   \n",
        "    각 토큰을 고유한 정수로 인코딩한다.\n",
        "2. 각 문장을 토큰화하고 각 문장의 시작과 끝을 나타내는   \n",
        "    'START_TOKEN' 및 'END_TOKEN'을 추가한다.\n",
        "3. 최대 길이 MAX_LENGTH인 40을 넘는 문장들은 필터링한다.\n",
        "4. MAX_LENGTH보다 길이가 짧은 문장들은 40에 맞도록 패딩 한다.\n",
        "\n",
        "## 1. 단어장(Vocabulary) 만들기\n",
        "\n",
        "우선 각 단어에 고유한 정수 인덱스를 부여하기 위해서 단어장(Vocabulary)을 만들어보겠습니다. 단어장을 만들 때는 질문과 답변 데이터셋을 모두 사용하여 만듭니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xgxc1sSoG_z6",
        "outputId": "1e619211-4c5a-4024-cccf-2e5cd7c3f6a6"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "print(\"살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\")\n",
        "\n",
        "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성. (Tensorflow 2.3.0 이상) (클라우드는 2.4 입니다)\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
        "print(\"슝=3 \")"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\n",
            "슝=3 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUr-QvYdCb0t",
        "outputId": "e3f9f9ca-6026-4c4c-d84d-91b6e46097fa"
      },
      "source": [
        "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
        "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START_TOKEN의 번호 : [8170]\n",
            "END_TOKEN의 번호 : [8171]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcMST4iRCesb"
      },
      "source": [
        "질문과 답변은 병렬적으로 구성되는 데이터셋이므로 두 샘플 수는 정확하게 일치해야 합니다! 둘 다 11,822개의 샘플이 저장되었습니다.\n",
        "\n",
        "임의로 22번째 샘플(인덱스 상으로는 21번 샘플)을 출력해서 질문과 답변이 병렬적으로 잘 저장되었는지, 확인해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpUJmPCxHMG8",
        "outputId": "6869892c-85fc-476c-bf29-4d6bfe42dc42"
      },
      "source": [
        "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
        "print(VOCAB_SIZE)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJDYrm97cQlR"
      },
      "source": [
        "현재 단어 집합 크기는 8,171개입니다. 디코딩 결과를 병렬적으로 나열하여 각 단어와 맵핑된 정수를 확인해봅시다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEMGUrdzcN6z"
      },
      "source": [
        "## 2. 각 단어를 고유한 정수로 인코딩(Integer encoding) & 패딩(Padding)\n",
        "\n",
        "위에서 tensorflow_datasets의 SubwordTextEncoder를 사용해서 tokenizer를 정의하고 Vocabulary를 만들었다면, tokenizer.encode()로 각 단어를 정수로 변환할 수 있고 또는 tokenizer.decode()를 통해 정수 시퀀스를 단어 시퀀스로 변환할 수 있습니다.\n",
        "\n",
        "예를 들어서 22번째 샘플을 tokenizer.encode()의 입력으로 사용해서 변환 결과를 봅시다.12`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLBlmoBIHMKL",
        "outputId": "5a95c4b5-1266-40bc-aae3-d7a4ae19d927"
      },
      "source": [
        "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
        "# 각 토큰을 고유한 정수로 변환\n",
        "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
        "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정수 인코딩 후의 21번째 질문 샘플: [5761, 610, 2490, 4163]\n",
            "정수 인코딩 후의 21번째 답변 샘플: [2356, 7510, 7, 6273, 97, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLA1jIuqcTKD"
      },
      "source": [
        "각 단어에 고유한 정수가 부여된 Vocabulary를 기준으로 단어 시퀀스가 정수 시퀀스로 인코딩된 결과를 확인할 수 있습니다. 위의 결과와 마찬가지로 질문과 답변 셋에 대해서 전부 정수 인코딩을 수행합니다. 이와 동시에 문장의 최대 길이를 정하고, 해당 길이로 패딩(padding) 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "godNjQ4aHMNZ",
        "outputId": "33cca378-4633-4756-9be0-21298192d499"
      },
      "source": [
        "questions_len = [len(s.split()) for s in questions]\n",
        "answers_len = [len(s.split()) for s in answers]\n",
        "\n",
        "print('질문의 최소 길이 : {}'.format(np.min(questions_len)))\n",
        "print('질문의 최대 길이 : {}'.format(np.max(questions_len)))\n",
        "print('질문의 평균 길이 : {}'.format(np.mean(questions_len)))\n",
        "print('답변의 최소 길이 : {}'.format(np.min(answers_len)))\n",
        "print('답변의 최대 길이 : {}'.format(np.max(answers_len)))\n",
        "print('답변의 평균 길이 : {}'.format(np.mean(answers_len)))"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문의 최소 길이 : 1\n",
            "질문의 최대 길이 : 16\n",
            "질문의 평균 길이 : 3.9409625306605767\n",
            "답변의 최소 길이 : 1\n",
            "답변의 최대 길이 : 24\n",
            "답변의 평균 길이 : 4.716146494121627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTk7OhLxHMPJ",
        "outputId": "18fcd2d5-d689-40ff-b652-ce93c45deb78"
      },
      "source": [
        "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
        "MAX_LENGTH = 25\n",
        "print(MAX_LENGTH)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i8-L3o7cafn"
      },
      "source": [
        "Questions, Answers 각각 7, 8개의 token일 경우 95%가 속하는 것을 볼 수 있다.\n",
        "하지만 대답 길이의 최대 24가 그렇게 큰 숫자가 아닌 것 같아 버리는 데이터 없이 가져가기로 했다. 그래서 MAX_LENGTH로 25를 지정하였음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCqWMX_zHMRv"
      },
      "source": [
        "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "  \n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "  \n",
        "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  \n",
        "  return tokenized_inputs, tokenized_outputs"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xpVgta-HMUt",
        "outputId": "8886655d-090c-4f4d-cd9c-90e73ccdf3b6"
      },
      "source": [
        "questions, answers = tokenize_and_filter(questions, answers)\n",
        "print('단어장의 크기 :',(VOCAB_SIZE))\n",
        "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
        "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어장의 크기 : 8172\n",
            "필터링 후의 질문 샘플 개수: 11817\n",
            "필터링 후의 답변 샘플 개수: 11817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ABk-59lcLNM"
      },
      "source": [
        "# 4. 모델 구성하기\n",
        "\n",
        "## 포지셔널 인코딩(Positional Encoding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV8T1xHhHMXK"
      },
      "source": [
        "# 포지셔널 인코딩 레이어\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    # 각도 배열 생성\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "\n",
        "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    # sin과 cosine이 교차되도록 재배열\n",
        "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
        "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
        "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
        "\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Xh3dCGjcoje"
      },
      "source": [
        "## 스케일드 닷-프로덕트 어텐션 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDwNGT_hHMa4"
      },
      "source": [
        "# 스케일드 닷 프로덕트 어텐션 함수\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # 가중치를 정규화\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # 패딩에 마스크 추가\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax적용\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "  return output"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj2Qsc7ncqbB"
      },
      "source": [
        "## 멀티 헤드 어텐션(Multi-head Attention) 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsJyS2SeHMcz"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # Q, K, V에 각각 Dense를 적용합니다\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # 스케일드 닷 프로덕트 어텐션 함수\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbpM_a9EcuY6"
      },
      "source": [
        "## 패딩 마스크(Padding Mask)\n",
        "## 디코더의 첫번째 서브층 : 셀프 어텐션과 룩-어헤드 마스크"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-i5SHJlHMfa"
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBofbS15cy74"
      },
      "source": [
        "## 인코더 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxwNXPXZHMiq"
      },
      "source": [
        "# 인코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZldvjowZc1kg"
      },
      "source": [
        "## 인코더 쌓기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fL0VnFGHMky"
      },
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # 포지셔널 인코딩\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  # num_layers만큼 쌓아올린 인코더의 층.\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLqVgR7kc2WV"
      },
      "source": [
        "## 디코더 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aePUNy4EHMoS"
      },
      "source": [
        "# 디코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "\n",
        "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
        "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvU2ljMvc4iF"
      },
      "source": [
        "## 디코더 쌓기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csAE4xSqHMqb"
      },
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "\n",
        "  # 패딩 마스크\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # 포지셔널 인코딩\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L09HAQrKch3K"
      },
      "source": [
        "## 교사 강요(Teacher Forcing) 사용하기\n",
        "\n",
        "훈련 과정에서는 이전 시점의 디코더 셀의 출력을 현재 시점의 디코더 셀의 입력으로 넣어주지 않고, 이전 시점의 실제값을 현재 시점의 디코더 셀의 입력값으로 하는 방법을 사용합니다. 그 이유는 이전 시점의 디코더 셀의 예측이 틀렸는데 이를 현재 시점의 디코더 셀의 입력으로 사용하면 현재 시점의 디코더 셀의 예측도 잘못될 가능성이 높고 이는 연쇄 작용으로 디코더 전체의 예측을 어렵게 합니다. 이런 상황이 반복되면 훈련 시간이 느려집니다. 만약 이 상황을 원하지 않는다면 이전 시점의 디코더 셀의 예측값 대신 실제값을 현재 시점의 디코더 셀의 입력으로 사용하는 방법을 사용할 수 있습니다. 이와 같이 RNN의 모든 시점에 대해서 이전 시점의 예측값 대신 실제값을 입력으로 주는 방법을 교사 강요라고 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZfXjCc3HMt5"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
        "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP1iVYj9c7BS"
      },
      "source": [
        "## 트랜스포머 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kdshxa--HMv7"
      },
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  # 인코더에서 패딩을 위한 마스크\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
        "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
        "  # 디코더에서 패딩을 위한 마스크\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  # 인코더\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  # 디코더\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  # 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQvreRE9c9ZB"
      },
      "source": [
        "## 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YOyDAb-HMyX",
        "outputId": "2e804d48-47d9-4a85-8777-71c6bf06eaf4"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "Model: \"transformer\""
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inputs (InputLayer)             [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "encoder (Functional)            (None, None, 256)    3146240     inputs[0][0]                     \n",
            "                                                                 enc_padding_mask[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Functional)            (None, None, 256)    3673600     dec_inputs[0][0]                 \n",
            "                                                                 encoder[0][0]                    \n",
            "                                                                 look_ahead_mask[0][0]            \n",
            "                                                                 dec_padding_mask[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "outputs (Dense)                 (None, None, 8172)   2100204     decoder[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,920,044\n",
            "Trainable params: 8,920,044\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ehKhSvYdAmM"
      },
      "source": [
        "## 손실함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-UfzLesHM1c"
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAACtCF-dBpK"
      },
      "source": [
        "## 커스텀 된 학습률(Learning rate)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D09IyHpGHM3a"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNXDnCw3dGib"
      },
      "source": [
        " ## 모델 컴파일"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2NHBoJiT6U2"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoVBNzcKdMFR"
      },
      "source": [
        "## 모델 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn6lB7mYT6Xy",
        "outputId": "6d848613-2815-4b22-9035-9d996ee222c7"
      },
      "source": [
        "EPOCHS = 20\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "185/185 [==============================] - 25s 82ms/step - loss: 2.3504 - accuracy: 0.0522\n",
            "Epoch 2/20\n",
            "185/185 [==============================] - 15s 81ms/step - loss: 1.9103 - accuracy: 0.0804\n",
            "Epoch 3/20\n",
            "185/185 [==============================] - 15s 81ms/step - loss: 1.6295 - accuracy: 0.0821\n",
            "Epoch 4/20\n",
            "185/185 [==============================] - 15s 81ms/step - loss: 1.5060 - accuracy: 0.0880\n",
            "Epoch 5/20\n",
            "185/185 [==============================] - 15s 81ms/step - loss: 1.4136 - accuracy: 0.0932\n",
            "Epoch 6/20\n",
            "185/185 [==============================] - 15s 81ms/step - loss: 1.3165 - accuracy: 0.1003\n",
            "Epoch 7/20\n",
            "185/185 [==============================] - 15s 81ms/step - loss: 1.2097 - accuracy: 0.1096\n",
            "Epoch 8/20\n",
            "185/185 [==============================] - 15s 81ms/step - loss: 1.0898 - accuracy: 0.1222\n",
            "Epoch 9/20\n",
            "185/185 [==============================] - 15s 82ms/step - loss: 0.9624 - accuracy: 0.1360\n",
            "Epoch 10/20\n",
            "185/185 [==============================] - 15s 81ms/step - loss: 0.8286 - accuracy: 0.1516\n",
            "Epoch 11/20\n",
            "185/185 [==============================] - 15s 81ms/step - loss: 0.6925 - accuracy: 0.1687\n",
            "Epoch 12/20\n",
            "185/185 [==============================] - 15s 81ms/step - loss: 0.5610 - accuracy: 0.1863\n",
            "Epoch 13/20\n",
            "185/185 [==============================] - 15s 81ms/step - loss: 0.4390 - accuracy: 0.2048\n",
            "Epoch 14/20\n",
            "185/185 [==============================] - 15s 81ms/step - loss: 0.3316 - accuracy: 0.2213\n",
            "Epoch 15/20\n",
            "185/185 [==============================] - 15s 82ms/step - loss: 0.2429 - accuracy: 0.2367\n",
            "Epoch 16/20\n",
            "185/185 [==============================] - 15s 81ms/step - loss: 0.1741 - accuracy: 0.2490\n",
            "Epoch 17/20\n",
            "185/185 [==============================] - 15s 81ms/step - loss: 0.1261 - accuracy: 0.2581\n",
            "Epoch 18/20\n",
            "185/185 [==============================] - 15s 81ms/step - loss: 0.0977 - accuracy: 0.2629\n",
            "Epoch 19/20\n",
            "185/185 [==============================] - 15s 81ms/step - loss: 0.0816 - accuracy: 0.2655\n",
            "Epoch 20/20\n",
            "185/185 [==============================] - 15s 81ms/step - loss: 0.0709 - accuracy: 0.2674\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f839d43c5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZRnONoIdLOG"
      },
      "source": [
        "# 5. 모델 평가하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTRSRYPdT6aY"
      },
      "source": [
        "def decoder_inference(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
        "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
        "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
        "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  # 디코더의 인퍼런스 단계\n",
        "  for i in range(MAX_LENGTH):\n",
        "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
        "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
        "    predictions = predictions[:, -1:, :]\n",
        "\n",
        "    # 현재 예측한 단어의 정수\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
        "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
        "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output_sequence, axis=0)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvb-U_-iT6cs"
      },
      "source": [
        "def sentence_generation(sentence):\n",
        "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
        "  prediction = decoder_inference(sentence)\n",
        "\n",
        "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('입력 : {}'.format(sentence))\n",
        "  print('출력 : {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "6NMDObxRT6fI",
        "outputId": "d870dd7f-cbaf-422c-c51b-0eff8315ab45"
      },
      "source": [
        "sentence_generation('뭐해?')"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 뭐해?\n",
            "출력 : 냉장고 파먹기 해보세요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'냉장고 파먹기 해보세요 .'"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "RcHJjcmKT6iX",
        "outputId": "caf63cba-d69b-4f19-e8a1-509e30e89dab"
      },
      "source": [
        "sentence_generation('심심해')"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 심심해\n",
            "출력 : 친구들과 연락해보세요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'친구들과 연락해보세요 .'"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "5w6PGfpLT6kR",
        "outputId": "3074739c-133e-4619-d8f6-7a77aae25c66"
      },
      "source": [
        "sentence_generation('공부하기 싫어')"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 공부하기 싫어\n",
            "출력 : 잠시 쉬어도 돼요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'잠시 쉬어도 돼요 .'"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zpf9QjtnT6mu",
        "outputId": "0c1412f7-cdd8-4e75-9884-0f365da4d45f"
      },
      "source": [
        "sentence_generation('배고파')"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 배고파\n",
            "출력 : 얼른 맛난 음식 드세요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'얼른 맛난 음식 드세요 .'"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "2WolEwXUT6pS",
        "outputId": "eeac4280-20e2-4c94-be73-658559bc076d"
      },
      "source": [
        "sentence_generation('어떤 노래 좋아해?')"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떤 노래 좋아해?\n",
            "출력 : 노래 연습 꾸준히 해보세요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'노래 연습 꾸준히 해보세요 .'"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "-qmEuTYUT6r1",
        "outputId": "574605a8-c1fd-4e07-a290-e0a96a494f81"
      },
      "source": [
        "sentence_generation('속상해')"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 속상해\n",
            "출력 : 좋은 일이 생길 거예요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'좋은 일이 생길 거예요 .'"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "sExMwNtFY5gb",
        "outputId": "84ac37a0-ca97-4bf6-f821-31958327ab90"
      },
      "source": [
        "sentence_generation('가끔 포기하고 싶어')"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 가끔 포기하고 싶어\n",
            "출력 : 가장 중요한 목표네요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'가장 중요한 목표네요 .'"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "HdpoSvCXZi7b",
        "outputId": "5a9ea7b5-3882-4ae3-ea91-c661ccfb3423"
      },
      "source": [
        "sentence_generation('노래방 가고 싶다')"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 노래방 가고 싶다\n",
            "출력 : 저랑 놀아요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'저랑 놀아요 .'"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dVyIExndnDz"
      },
      "source": [
        "# 프로젝트 정리\n",
        "\n",
        "1. 텍스트 전처리 과정을 수행하였다.\n",
        "2. 병렬 데이터의 토크나이징 방법을 배웠다.\n",
        "3. 트랜스포머 모델을 구현하는 흐름을 익혔다.\n",
        "4. 대답을 하는 챗봇을 구현하였다.\n",
        "\n",
        "# 보충할 점\n",
        "트랜스포머 모델을 이해하기 위해서는 RNN 모델에 대한 이해가 더 필요해 보이고, 구현하는 것보다 이론을 다시 살펴보며 이해하는 것도 필요하다고 느껴짐\n",
        "\n",
        "# 관련 논문\n",
        "\n",
        "- 논문 제목: Attention is all you need\n",
        "- 링크 바로 가기: [클릭](https://arxiv.org/abs/1706.03762)\n",
        "- 다운로드 바로 하기: [클릭](https://arxiv.org/pdf/1706.03762.pdf)"
      ]
    }
  ]
}